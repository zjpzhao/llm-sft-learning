{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.00927357032457496,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0001545595054095827,
      "grad_norm": 0.5362735986709595,
      "learning_rate": 0.0,
      "loss": 1.5764,
      "step": 1
    },
    {
      "epoch": 0.0003091190108191654,
      "grad_norm": 0.8710219860076904,
      "learning_rate": 4e-05,
      "loss": 2.1039,
      "step": 2
    },
    {
      "epoch": 0.0004636785162287481,
      "grad_norm": 0.5220493674278259,
      "learning_rate": 8e-05,
      "loss": 1.6777,
      "step": 3
    },
    {
      "epoch": 0.0006182380216383308,
      "grad_norm": 0.7067542672157288,
      "learning_rate": 0.00012,
      "loss": 1.9187,
      "step": 4
    },
    {
      "epoch": 0.0007727975270479134,
      "grad_norm": 0.691577136516571,
      "learning_rate": 0.00016,
      "loss": 1.75,
      "step": 5
    },
    {
      "epoch": 0.0009273570324574962,
      "grad_norm": 0.8712944388389587,
      "learning_rate": 0.0002,
      "loss": 1.5112,
      "step": 6
    },
    {
      "epoch": 0.0010819165378670788,
      "grad_norm": 1.5610002279281616,
      "learning_rate": 0.00019636363636363636,
      "loss": 1.1399,
      "step": 7
    },
    {
      "epoch": 0.0012364760432766616,
      "grad_norm": 1.2388345003128052,
      "learning_rate": 0.00019272727272727274,
      "loss": 1.3302,
      "step": 8
    },
    {
      "epoch": 0.0013910355486862441,
      "grad_norm": 0.9382475018501282,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.1961,
      "step": 9
    },
    {
      "epoch": 0.0015455950540958269,
      "grad_norm": 0.6166884303092957,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.1383,
      "step": 10
    },
    {
      "epoch": 0.0017001545595054096,
      "grad_norm": 0.5257995128631592,
      "learning_rate": 0.00018181818181818183,
      "loss": 0.9207,
      "step": 11
    },
    {
      "epoch": 0.0018547140649149924,
      "grad_norm": 0.386997252702713,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.0027,
      "step": 12
    },
    {
      "epoch": 0.002009273570324575,
      "grad_norm": 0.5260756611824036,
      "learning_rate": 0.00017454545454545454,
      "loss": 0.9098,
      "step": 13
    },
    {
      "epoch": 0.0021638330757341576,
      "grad_norm": 0.4132465422153473,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.0712,
      "step": 14
    },
    {
      "epoch": 0.00231839258114374,
      "grad_norm": 0.6231567859649658,
      "learning_rate": 0.00016727272727272728,
      "loss": 0.888,
      "step": 15
    },
    {
      "epoch": 0.002472952086553323,
      "grad_norm": 0.5065065026283264,
      "learning_rate": 0.00016363636363636366,
      "loss": 0.8532,
      "step": 16
    },
    {
      "epoch": 0.0026275115919629057,
      "grad_norm": 0.42925241589546204,
      "learning_rate": 0.00016,
      "loss": 0.9832,
      "step": 17
    },
    {
      "epoch": 0.0027820710973724882,
      "grad_norm": 0.46575111150741577,
      "learning_rate": 0.00015636363636363637,
      "loss": 1.3248,
      "step": 18
    },
    {
      "epoch": 0.002936630602782071,
      "grad_norm": 0.503828227519989,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.0196,
      "step": 19
    },
    {
      "epoch": 0.0030911901081916537,
      "grad_norm": 0.4843534529209137,
      "learning_rate": 0.0001490909090909091,
      "loss": 0.8529,
      "step": 20
    },
    {
      "epoch": 0.0032457496136012367,
      "grad_norm": 0.7367231845855713,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.8965,
      "step": 21
    },
    {
      "epoch": 0.0034003091190108192,
      "grad_norm": 0.6308271288871765,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.9507,
      "step": 22
    },
    {
      "epoch": 0.0035548686244204018,
      "grad_norm": 0.4049600660800934,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.9667,
      "step": 23
    },
    {
      "epoch": 0.0037094281298299847,
      "grad_norm": 0.358246386051178,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.9691,
      "step": 24
    },
    {
      "epoch": 0.0038639876352395673,
      "grad_norm": 0.5183965563774109,
      "learning_rate": 0.00013090909090909093,
      "loss": 1.042,
      "step": 25
    },
    {
      "epoch": 0.00401854714064915,
      "grad_norm": 0.3470596373081207,
      "learning_rate": 0.00012727272727272728,
      "loss": 1.0202,
      "step": 26
    },
    {
      "epoch": 0.004173106646058733,
      "grad_norm": 0.3669678568840027,
      "learning_rate": 0.00012363636363636364,
      "loss": 1.022,
      "step": 27
    },
    {
      "epoch": 0.004327666151468315,
      "grad_norm": 0.31900426745414734,
      "learning_rate": 0.00012,
      "loss": 0.9143,
      "step": 28
    },
    {
      "epoch": 0.004482225656877898,
      "grad_norm": 0.45819318294525146,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.911,
      "step": 29
    },
    {
      "epoch": 0.00463678516228748,
      "grad_norm": 0.400046706199646,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.8506,
      "step": 30
    },
    {
      "epoch": 0.004791344667697064,
      "grad_norm": 0.3078283965587616,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.8602,
      "step": 31
    },
    {
      "epoch": 0.004945904173106646,
      "grad_norm": 0.37059682607650757,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.8671,
      "step": 32
    },
    {
      "epoch": 0.005100463678516229,
      "grad_norm": 0.3344459533691406,
      "learning_rate": 0.00010181818181818181,
      "loss": 1.0019,
      "step": 33
    },
    {
      "epoch": 0.005255023183925811,
      "grad_norm": 0.5406186580657959,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.8616,
      "step": 34
    },
    {
      "epoch": 0.005409582689335394,
      "grad_norm": 0.3318367600440979,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.9946,
      "step": 35
    },
    {
      "epoch": 0.0055641421947449764,
      "grad_norm": 0.334582656621933,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.8771,
      "step": 36
    },
    {
      "epoch": 0.00571870170015456,
      "grad_norm": 0.3318731486797333,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.8247,
      "step": 37
    },
    {
      "epoch": 0.005873261205564142,
      "grad_norm": 0.3894120156764984,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.7351,
      "step": 38
    },
    {
      "epoch": 0.006027820710973725,
      "grad_norm": 0.3440994918346405,
      "learning_rate": 8e-05,
      "loss": 1.0629,
      "step": 39
    },
    {
      "epoch": 0.0061823802163833074,
      "grad_norm": 0.9422336220741272,
      "learning_rate": 7.636363636363637e-05,
      "loss": 1.1805,
      "step": 40
    },
    {
      "epoch": 0.00633693972179289,
      "grad_norm": 0.3978075683116913,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.8995,
      "step": 41
    },
    {
      "epoch": 0.006491499227202473,
      "grad_norm": 0.32558727264404297,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.9647,
      "step": 42
    },
    {
      "epoch": 0.006646058732612056,
      "grad_norm": 0.46000948548316956,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.8788,
      "step": 43
    },
    {
      "epoch": 0.0068006182380216385,
      "grad_norm": 0.3180811107158661,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.9107,
      "step": 44
    },
    {
      "epoch": 0.006955177743431221,
      "grad_norm": 0.34706735610961914,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.9723,
      "step": 45
    },
    {
      "epoch": 0.0071097372488408035,
      "grad_norm": 0.32583722472190857,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.9404,
      "step": 46
    },
    {
      "epoch": 0.007264296754250386,
      "grad_norm": 0.3558942675590515,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.8141,
      "step": 47
    },
    {
      "epoch": 0.0074188562596599695,
      "grad_norm": 0.36638152599334717,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 1.2386,
      "step": 48
    },
    {
      "epoch": 0.007573415765069552,
      "grad_norm": 0.3516392707824707,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.8425,
      "step": 49
    },
    {
      "epoch": 0.0077279752704791345,
      "grad_norm": 0.2976590394973755,
      "learning_rate": 4e-05,
      "loss": 1.0598,
      "step": 50
    },
    {
      "epoch": 0.007882534775888718,
      "grad_norm": 0.3195165991783142,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 1.0404,
      "step": 51
    },
    {
      "epoch": 0.0080370942812983,
      "grad_norm": 0.35871341824531555,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.8985,
      "step": 52
    },
    {
      "epoch": 0.008191653786707883,
      "grad_norm": 0.4033541977405548,
      "learning_rate": 2.909090909090909e-05,
      "loss": 1.0062,
      "step": 53
    },
    {
      "epoch": 0.008346213292117466,
      "grad_norm": 0.3446820378303528,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 1.1718,
      "step": 54
    },
    {
      "epoch": 0.008500772797527048,
      "grad_norm": 0.33394068479537964,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.7933,
      "step": 55
    },
    {
      "epoch": 0.00865533230293663,
      "grad_norm": 0.3210609555244446,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.9986,
      "step": 56
    },
    {
      "epoch": 0.008809891808346213,
      "grad_norm": 0.33574438095092773,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.8766,
      "step": 57
    },
    {
      "epoch": 0.008964451313755796,
      "grad_norm": 0.3175014853477478,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.7732,
      "step": 58
    },
    {
      "epoch": 0.009119010819165378,
      "grad_norm": 0.31624650955200195,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.8374,
      "step": 59
    },
    {
      "epoch": 0.00927357032457496,
      "grad_norm": 0.2913372218608856,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.8827,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5726714157219840.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
